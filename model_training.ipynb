{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "The following notebook trains two deep learning models:\n",
    "1. **SheetClassifier**: A model for identifying images of metal sheets with defects, classifying them by their defect.\n",
    "2. **SheetHighlighter**: A model which takes images of metal sheets with defects and highlights the defects in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, epochs:int, learning_rate:float, model_type:nn.Module, dataset:Dataset, batch_size:int = 10, criterion = nn.CrossEntropyLoss, show:bool = False):\n",
    "        self.epochs, self.lr, self.model_type, self.dataset, self.batch_size, self.criterion_type, self.show = epochs, learning_rate, model_type, dataset, batch_size, criterion, show\n",
    "        self.create_dataloaders()\n",
    "\n",
    "    def run_experiment(self, model = None):\n",
    "        # Runs the experiment with the given criteria, returning a trained model\n",
    "        #training_losses = [] # For graphing, should we choose\n",
    "\n",
    "        self.model = self.model_type() if not model else model\n",
    "        self.has_acc = hasattr(self.model, 'get_accuracy')\n",
    "        self.criterion = self.criterion_type()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            for i, (x,y) in enumerate(self.training_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                yhat = self.model(x)\n",
    "                loss = self.criterion(yhat, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                if self.has_acc: running_acc += self.model.get_accuracy(yhat, y)\n",
    "            training_acc = running_acc / len(self.training_loader)\n",
    "            training_loss = running_loss / len(self.training_loader)\n",
    "            if (epoch % 10 == 0 or training_acc >= .99) and self.show:\n",
    "                msg = f'Epoch [{epoch + 1}/{self.epochs}], Train Loss: {training_loss:.2f}'\n",
    "                if self.has_acc: msg+=f', Accuracy: {training_acc:.2f}'\n",
    "                print(msg)\n",
    "                if training_acc >= .99: break\n",
    "        if self.show: print('Experiment Complete')\n",
    "        return self.model\n",
    "\n",
    "    def evaluate_model(self, model:nn.Module = None, loader = None):\n",
    "        # Evaluates the trained model\n",
    "        if not loader: loader = self.testing_loader\n",
    "        if not model: model = self.model\n",
    "        has_acc = hasattr(model, 'get_accuracy')\n",
    "        criterion = self.criterion_type()\n",
    "\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for i, (x,y) in enumerate(loader):\n",
    "            yhat = model(x)\n",
    "            loss = criterion(yhat, y)\n",
    "            running_loss += loss.item()\n",
    "            if has_acc: running_acc += model.get_accuracy(yhat, y)\n",
    "        msg = f'[Evaluation over {len(loader)} Batches], Test Loss: {running_loss/len(loader):.2f}'\n",
    "        if has_acc: msg+=f', Accuracy: {running_acc/len(loader):.2f}'\n",
    "        print(msg)\n",
    "        return model\n",
    "    \n",
    "    def create_dataloaders(self):\n",
    "        num_items = len(self.dataset)\n",
    "        num_train = round(num_items * 0.8)\n",
    "        num_val = num_items - num_train\n",
    "        \n",
    "        self.training_dataset, self.testing_dataset = random_split(self.dataset, [num_train, num_val])\n",
    "        self.training_loader = DataLoader(self.training_dataset,  batch_size=self.batch_size, shuffle=True)\n",
    "        self.testing_loader = DataLoader(self.testing_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "         \n",
    "    def calculate_accuracy(self, predictions:list, true_y:list):\n",
    "        accuracy_df = pd.DataFrame(zip(predictions, true_y),columns=['predictions','y_values'])\n",
    "        accuracy_df.predictions = accuracy_df.predictions >= 0.5\n",
    "        accuracy_df.y_values = accuracy_df.y_values == 1\n",
    "        accuracy_df = accuracy_df.predictions == accuracy_df.y_values\n",
    "        accuracy = len(accuracy_df[accuracy_df])/len(accuracy_df)\n",
    "        \n",
    "        if self.show: print('Our Model Accuracy', accuracy)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SheetClassifier import SheetClassifier\n",
    "from datasets.ClassificationSet import ClassificationSet\n",
    "\n",
    "class_set = ClassificationSet('/home/sms/Documents/hobbies/projects/ml_data/metal_sheets')\n",
    "trainer = Trainer(10, 0.003, SheetClassifier, class_set, 10, criterion=nn.CrossEntropyLoss, show=True)\n",
    "sc = SheetClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Training Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evaluation over 60 Batches], Test Loss: 4.96, Accuracy: 0.31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SheetClassifier(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lin1): Linear(in_features=65536, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate_model(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 5.13, Accuracy: 0.63\n",
      "Epoch [2/10], Train Loss: 1.06, Accuracy: 0.88\n",
      "Epoch [3/10], Train Loss: 0.26, Accuracy: 0.96\n",
      "Epoch [4/10], Train Loss: 0.17, Accuracy: 0.97\n",
      "Epoch [5/10], Train Loss: 0.10, Accuracy: 0.98\n",
      "Epoch [6/10], Train Loss: 0.05, Accuracy: 0.99\n",
      "Epoch [7/10], Train Loss: 0.05, Accuracy: 0.99\n",
      "Epoch [8/10], Train Loss: 0.06, Accuracy: 0.98\n",
      "Epoch [9/10], Train Loss: 0.06, Accuracy: 0.99\n",
      "Epoch [10/10], Train Loss: 0.11, Accuracy: 0.98\n",
      "Experiment Complete\n"
     ]
    }
   ],
   "source": [
    "sc = trainer.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evaluation over 60 Batches], Test Loss: 4.69, Accuracy: 0.73\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SheetClassifier(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lin1): Linear(in_features=65536, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate_model(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Highlighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SheetHighlighter import SheetHighlighter\n",
    "from datasets.HighlighterSet import HighlighterSet\n",
    "\n",
    "highlight_set = HighlighterSet('/home/sms/Documents/hobbies/projects/ml_data/metal_sheets')\n",
    "trainer = Trainer(11, 0.003, SheetHighlighter, highlight_set, 10, criterion=nn.BCELoss, show=True)\n",
    "sh = SheetHighlighter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evaluation over 60 Batches], Test Loss: 1.33, Accuracy: 0.42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SheetHighlighter(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate_model(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/11], Train Loss: 0.05, Accuracy: 0.98\n",
      "Epoch [2/11], Train Loss: 0.03, Accuracy: 0.99\n",
      "Experiment Complete\n"
     ]
    }
   ],
   "source": [
    "sh = trainer.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evaluation over 60 Batches], Test Loss: 0.02, Accuracy: 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SheetHighlighter(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate_model(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
